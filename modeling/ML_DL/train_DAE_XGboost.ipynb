{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Input,Dropout,Embedding,LSTM\n",
    "from keras.optimizers import RMSprop,Adam,Nadam\n",
    "from keras.preprocessing import sequence \n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import tensorflow\n",
    "import time \n",
    "\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Visualisation class\n",
    "class Visualization:\n",
    "    \n",
    "    labels=[\"Normal\",\"Anomaly\"]\n",
    "    \n",
    "    def drow_confusion_matrix(self,y,ypred):\n",
    "        matrix=confusion_matrix(y,ypred)\n",
    "        plt.figure(figsize=(15,10))\n",
    "        colors=[\"indianred\",\"lightseagreen\"]\n",
    "        sns.heatmap(matrix,xticklabels=self.labels,yticklabels=self.labels,cmap=colors,annot=True,fmt=\"d\")\n",
    "        plt.title(\"confusion Matrix\")\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    def drow_anomaly(self,y,error,threshold):\n",
    "        groupsDF=pd.DataFrame({\n",
    "            \"error\":error,\n",
    "            \"true\":y\n",
    "        }).groupby(\"true\")\n",
    "        \n",
    "        figure , axes= plt.subplots(figsize=(12,8))\n",
    "        for name,group in groupsDF:\n",
    "            axes.plot(\n",
    "                      group.index,group.error,marker=\"x\" if name == 1 else \"o\",linestyle='',\n",
    "                      color='r' if name==1 else \"teal\" , label=\"Anomaly\" if name==1 else \"Normal\"\n",
    "                     )\n",
    "            \n",
    "        axes.hlines(threshold,axes.get_xlim()[0],axes.get_xlim()[1],color=\"b\",zorder=100,label='Thershold')\n",
    "        axes.legend()\n",
    "        plt.title(\"Anomalie\")\n",
    "        plt.xlabel(\"Data\")\n",
    "        plt.ylabel(\"Error\")\n",
    "        plt.show()\n",
    "            \n",
    "    \n",
    "    def drow_error(self,error,threshold):\n",
    "        plt.plot(error,marker=\"o\",ms=3.5,linestyle=\"\",label=\"Point\")\n",
    "        plt.hlines(threshold,xmin=0,xmax=len(error)-1,colors=\"b\",zorder=100,label=\"Threshold\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Reconstruction Error\")\n",
    "        plt.ylabel(\"Error\")\n",
    "        plt.xlabel(\"Data\")\n",
    "        plt.show()\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278060, 116)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv(\"../../data/full_data_small_datased.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_df(df):\n",
    "    dic={}\n",
    "    for c in df.columns :\n",
    "        if (df[c].dtype ==\"object\"):\n",
    "            encoder = LabelEncoder()\n",
    "            encoder.fit(df[c])\n",
    "            df[c]=encoder.transform(df[c])\n",
    "            dic[c]=encoder\n",
    "    with open(\"./models/LabelEncoders_dic.pickle\",\"wb\") as f:\n",
    "        pickle.dump(dic,f)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_dataframe(df):\n",
    "    df = shuffle(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliser_all_columns(df):\n",
    "    diction={}\n",
    "    \n",
    "    for c in df.columns :\n",
    "        scaler=MinMaxScaler(feature_range=(0,1)).fit(df[c].values.reshape(-1,1))\n",
    "        diction[c]=scaler        \n",
    "        df[c]=scaler.transform(df[c].values.reshape(-1,1))\n",
    "    with open(\"./models/MinMaxScalers_dic.pickle\",\"wb\") as f:\n",
    "        pickle.dump(diction,f)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=transformer_df(df)\n",
    "df=normaliser_all_columns(df)\n",
    "df=shuffle_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(df.drop(labels=[\"Class\"],axis=1),df[\"Class\"],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(xtrain,xtest,ytrain,ytest):\n",
    "    noise_factor=0.3\n",
    "    xtrain_noise=xtrain + noise_factor *np.random.normal(loc=0.0,scale=1.0,size=xtrain.shape)\n",
    "    xtest_noise=xtest + noise_factor *np.random.normal(loc=0.0,scale=1.0,size=xtest.shape)\n",
    "    ytrain_noise=ytrain + noise_factor *np.random.normal(loc=0.0,scale=1.0,size=ytrain.shape)\n",
    "    ytest_noise=ytest + noise_factor *np.random.normal(loc=0.0,scale=1.0,size=ytest.shape)\n",
    "    xtrain_noise=np.clip(xtrain_noise,0.,1.)\n",
    "    xtest_noise=np.clip(xtest_noise,0.,1.)\n",
    "    ytrain_noise=np.clip(ytrain_noise,0.,1.)\n",
    "    ytest_noise=np.clip(ytest_noise,0.,1.)\n",
    "    return xtrain_noise,xtest_noise,ytrain_noise,ytest_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_noise,xtest_noise,ytrain_noise,ytest_noise=add_noise(xtrain,xtest,ytrain,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train the ML algorithm using the output of the DAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the DAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dae(input_dim):\n",
    "    \n",
    "    dae_input=Input(shape=(input_dim,)) #Define the input layer\n",
    "    \n",
    "    encoded= Dense(units=input_dim,activation=\"tanh\")(dae_input) \n",
    "    encoded= Dense(units=int(input_dim/2),activation=\"tanh\")(encoded) \n",
    "    encoded= Dense(units=int(input_dim/4),activation=\"tanh\")(encoded)\n",
    "    encoded= Dense(units=int(input_dim/8),activation=\"tanh\")(encoded)\n",
    "    encoded= Dense(units=10,activation=\"tanh\")(encoded)\n",
    "    encoded= Dense(units=3,activation=\"tanh\")(encoded)\n",
    "    encoded= Dense(units=int(input_dim/8),activation=\"tanh\")(encoded)\n",
    "    decoded= Dense(units=int(input_dim/4),activation=\"tanh\")(encoded)\n",
    "    decoded= Dense(units=int(input_dim/2),activation=\"tanh\")(decoded)\n",
    "    decoded= Dense(units=input_dim,activation=\"tanh\")(decoded)\n",
    "    decoded= Dense(units=input_dim,activation=\"softmax\",name='decoded')(decoded) #softmax return a vector of probabilty describing the importance of each attribute \n",
    "    autoecoder=Model(dae_input,decoded)# the input layer and the output layer \n",
    "    autoecoder.summary()\n",
    "    autoecoder.compile(optimizer=RMSprop(),loss=\"mean_squared_error\",metrics=[\"mae\"])\n",
    "    plot_model(autoecoder,to_file='dae.png',show_shapes=True)\n",
    "    return autoecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 115)               13340     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 57)                6612      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 28)                1624      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 14)                406       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                150       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 28)                420       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 57)                1653      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 115)               6670      \n",
      "_________________________________________________________________\n",
      "decoded (Dense)              (None, 115)               13340     \n",
      "=================================================================\n",
      "Total params: 44,304\n",
      "Trainable params: 44,304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "denosed_autoecoder = create_dae(xtrain.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 222448 samples, validate on 55612 samples\n",
      "Epoch 1/10\n",
      "222448/222448 [==============================] - 6s 28us/step - loss: 0.2769 - mae: 0.3585 - val_loss: 0.2755 - val_mae: 0.3569\n",
      "Epoch 2/10\n",
      "222448/222448 [==============================] - 6s 26us/step - loss: 0.2769 - mae: 0.3584 - val_loss: 0.2755 - val_mae: 0.3569\n",
      "Epoch 3/10\n",
      "222448/222448 [==============================] - 6s 26us/step - loss: 0.2768 - mae: 0.3584 - val_loss: 0.2750 - val_mae: 0.3569\n",
      "Epoch 4/10\n",
      "222448/222448 [==============================] - 6s 26us/step - loss: 0.2764 - mae: 0.3584 - val_loss: 0.2750 - val_mae: 0.3569\n",
      "Epoch 5/10\n",
      "222448/222448 [==============================] - 8s 37us/step - loss: 0.2764 - mae: 0.3584 - val_loss: 0.2750 - val_mae: 0.3569\n",
      "Epoch 6/10\n",
      "222448/222448 [==============================] - 6s 27us/step - loss: 0.2764 - mae: 0.3584 - val_loss: 0.2750 - val_mae: 0.3569\n",
      "Epoch 7/10\n",
      "222448/222448 [==============================] - 6s 26us/step - loss: 0.2764 - mae: 0.3584 - val_loss: 0.2750 - val_mae: 0.3569\n",
      "Epoch 8/10\n",
      "222448/222448 [==============================] - 9s 38us/step - loss: 0.2764 - mae: 0.3584 - val_loss: 0.2750 - val_mae: 0.3569\n",
      "Epoch 9/10\n",
      "222448/222448 [==============================] - 6s 27us/step - loss: 0.2764 - mae: 0.3584 - val_loss: 0.2750 - val_mae: 0.3569\n",
      "Epoch 10/10\n",
      "222448/222448 [==============================] - 6s 27us/step - loss: 0.2764 - mae: 0.3584 - val_loss: 0.2750 - val_mae: 0.3569\n"
     ]
    }
   ],
   "source": [
    "#hyperparametrs :\n",
    "batchsize=100\n",
    "epoch=10\n",
    "start_time = time.time() \n",
    "history = denosed_autoecoder.fit(xtrain_noise,xtrain,\n",
    "              batch_size=batchsize,\n",
    "              epochs=epoch,\n",
    "              verbose=1,\n",
    "              shuffle=True,\n",
    "              validation_data=(xtest_noise,xtest),\n",
    "              callbacks=[TensorBoard(log_dir=\"../logs/Denoiseautoencoder\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xtrain_ml=denosed_autoecoder.predict(xtrain_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/houssem/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/houssem/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 112.1256456375122 seconds ---\n"
     ]
    }
   ],
   "source": [
    "xgb = xgb.fit(pd.DataFrame(xtrain_ml), pd.DataFrame(ytrain))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-abe275e7f72528e4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-abe275e7f72528e4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {\"../logs/Denoiseautoencoder/\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the predict output dataset from DAE model to use it as the test dataset of the ML algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.0750336647033691 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() \n",
    "xtest_ml=pd.DataFrame(denosed_autoecoder.predict(xtest_noise))\n",
    "y_pred = xgb.predict(xtest_ml)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluer lalgorithme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      8070\n",
      "         1.0       1.00      1.00      1.00     47542\n",
      "\n",
      "    accuracy                           1.00     55612\n",
      "   macro avg       1.00      1.00      1.00     55612\n",
      "weighted avg       1.00      1.00      1.00     55612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score : 0.9999640365388766\n",
      "accuracy_score : 0.9999640365388766\n",
      "recall_score : 0.9999640365388766\n",
      "f1_score : 0.9999640365388766\n",
      "roc_auc_score : 0.999927525114818\n",
      "True_positive : 47541, False_positive : 1, True_negative : 8069, False_negative : 1\n"
     ]
    }
   ],
   "source": [
    "print('precision_score : '+str(precision_score(ytest, y_pred, average='weighted')))\n",
    "print('accuracy_score : '+str(accuracy_score(ytest, y_pred)))\n",
    "print('recall_score : '+str(recall_score(ytest, y_pred, average='weighted')))\n",
    "print('f1_score : '+str(f1_score(ytest, y_pred, average='weighted')))\n",
    "print('roc_auc_score : '+str(roc_auc_score(ytest,y_pred))) # TruePositive,TrueNegative\n",
    "tn, fp, fn, tp = confusion_matrix(ytest, y_pred).ravel()\n",
    "print('True_positive : '+str(tp)+', False_positive : '+str(fp)+', True_negative : '+str(tn)+', False_negative : '+str(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz=Visualization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz.drow_confusion_matrix(ytest,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the models to disk\n",
    "denosed_autoecoder.save(\"./models/dae.h5\")\n",
    "pickle.dump(xgb, open('./models/xgb.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
